{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f752a-7392-4b5f-8f71-c4174c3efe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d02679-8f6b-476d-9714-4b225cd0322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKNUM=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907865-d7eb-4e7d-a1aa-976ad603b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dms_indices = list(range(TASKNUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba935de1-b3e8-4e10-9bb1-66d50e8d10e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../bindinggym_offline/input/BindingGYM_AL.csv\")\n",
    "idx2name = {i: train_df.loc[i, 'DMS_id'] for i in range(TASKNUM)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e613f4-2e64-46d6-9c10-31987fe5882d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "esm_dfs = [pd.read_csv(f\"../bindinggym_offline/modelzoo/esm2/output/{idx2name[i]}.csv\") for i in range(TASKNUM)]\n",
    "proteinmpnn_dfs = [pd.read_csv(f\"../bindinggym_offline/modelzoo/proteinmpnn//output/{idx2name[i]}.csv\") for i in range(TASKNUM)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303b61f-0567-48ed-8ae9-80cb8086595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablang_dfs = [pd.read_csv(f\"outputs/greedy_0.0/dms_ablang2_{i}_N-50_ini-1/predictions_cycle_0.csv\" ) for i in range(TASKNUM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9ba0f-bc3b-4b88-a722-ee7de92870e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union, Tuple\n",
    "\n",
    "def calculate_mean_similarity(latent_matrix: np.ndarray):\n",
    "    \n",
    "    # 入力チェック\n",
    "    if not isinstance(latent_matrix, np.ndarray):\n",
    "        raise TypeError(\"latent_matrix must be numpy.ndarray\")\n",
    "    \n",
    "    if len(latent_matrix.shape) != 2:\n",
    "        raise ValueError(\"latent_matrix must be 2-dimensional\")\n",
    "        \n",
    "    N, H = latent_matrix.shape\n",
    "    \n",
    "    if N < 2:\n",
    "        raise ValueError(\"Number of samples must be greater than 1\")\n",
    "    \n",
    "    # 各ベクトルのノルムを計算\n",
    "    norms = np.linalg.norm(latent_matrix, axis=1, keepdims=True)\n",
    "    # ゼロ除算を防ぐ\n",
    "    norms = np.where(norms == 0, 1e-8, norms)\n",
    "    \n",
    "    # 正規化された行列を計算\n",
    "    normalized_matrix = latent_matrix / norms\n",
    "    \n",
    "    # コサイン類似度行列を計算\n",
    "    similarity_matrix = np.dot(normalized_matrix, normalized_matrix.T)\n",
    "    # 対角要素を0にする（自己との類似度は除外）\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "    \n",
    "    # 平均コサイン類似度を計算\n",
    "    mean_similarity = similarity_matrix.sum() / (N * (N-1))\n",
    "        \n",
    "    return mean_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1b137-08d2-4780-8fa0-a15b3d3ec840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import root_mean_squared_error, ndcg_score\n",
    "\n",
    "from sklearn.preprocessing import scale, minmax_scale\n",
    "\n",
    "def calc_test(true_scores, pred_scores, k=10):\n",
    "    rho, _ = spearmanr(true_scores, pred_scores)\n",
    "\n",
    "    # RMSE\n",
    "    rmse = root_mean_squared_error(true_scores, pred_scores)\n",
    "\n",
    "    # NDCG@k\n",
    "    std_tgts = minmax_scale([true_scores], (0, 5), axis=1)\n",
    "    ndcg_val = ndcg_score(std_tgts,[pred_scores], k=k)\n",
    "\n",
    "    result ={\n",
    "        'spearman': rho,\n",
    "        'rmse': rmse,\n",
    "        'ndcg': ndcg_val\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def compute_test_performance(df, cycle_list, k=10):\n",
    "    \"\"\"\n",
    "    cycle_list: [1, 2, 3, ...] のように評価対象となるサイクル番号をリスト化\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    df_test = df[df['is_test'] == True].copy()\n",
    "\n",
    "    for c in cycle_list:\n",
    "        pred_col = f'cycle_{c}_preds'\n",
    "        if pred_col not in df_test.columns:\n",
    "            continue  # そのサイクルの予測列がなければスキップ\n",
    "        result = calc_test(df_test['DMS_score'].values, df_test[pred_col].values, k=k)\n",
    "        result[\"cycle\"] = c\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def calc_recall_precision(d, df, p=None, k=None, topk=10):\n",
    "    # p is the percentage of the top 1%\n",
    "    # k is the kth top\n",
    "    df_pool = df[~df[\"is_test\"]].copy()\n",
    "    if p is not None:\n",
    "        df_pool[\"top\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].quantile(1-p)\n",
    "    elif k is not None:\n",
    "        df_pool[\"top\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].sort_values(ascending=False).iloc[k-1]\n",
    "    else:\n",
    "        raise ValueError(\"Either p or k must be provided\")\n",
    "    df_pool[\"top_10\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].quantile(0.9)\n",
    "    results = []\n",
    "    df_selected = df_pool[df_pool[\"selected_cycle\"]>=0].copy()\n",
    "    for cycle in range(d[\"active_learning\"][\"M_cycles\"]+1):\n",
    "        df_cycle = df_selected[df_selected[\"selected_cycle\"]<=cycle].copy()\n",
    "        top1_recall = df_cycle[\"top\"].sum()/df_pool[\"top\"].sum()\n",
    "        top1_precision = df_cycle[\"top\"].sum()/len(df_cycle[\"top\"])\n",
    "        top10_recall = df_cycle[\"top_10\"].sum()/df_pool[\"top_10\"].sum()\n",
    "        top10_precision = df_cycle[\"top_10\"].sum()/len(df_cycle[\"top_10\"])\n",
    "        top_mean_1 = df_cycle.sort_values(f\"DMS_score\", ascending=False).head(topk)[\"DMS_score\"].mean()\n",
    "        top_mean_2 = df_cycle.sort_values(f\"DMS_score\", ascending=False).head(topk*2)[\"DMS_score\"].mean()\n",
    "        top_mean_3 = df_cycle.sort_values(f\"DMS_score\", ascending=False).head(topk*3)[\"DMS_score\"].mean()\n",
    "        results.append({\"cycle\": cycle+1, \"recall\": top1_recall, \"precision\": top1_precision, \"recall_10\": top10_recall, \"precision_10\": top10_precision, \"top_mean_1\": top_mean_1,\"top_mean_2\": top_mean_2,\"top_mean_3\": top_mean_3})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def calc_recall_precision_greedy(d, df, p=None, k=None, N=600, topk=10):\n",
    "    df_pool = df[~df[\"is_test\"]].copy()\n",
    "    if p is not None:\n",
    "        df_pool[\"top\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].quantile(1-p)\n",
    "    elif k is not None:\n",
    "        df_pool[\"top\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].sort_values(ascending=False).iloc[k-1]\n",
    "    else:\n",
    "        raise ValueError(\"Either p or k must be provided\")\n",
    "    df_pool[\"top_10\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].quantile(0.9)\n",
    "    results = []\n",
    "    df_selected_all = df_pool[df_pool[\"selected_cycle\"]>=0].copy()\n",
    "    for cycle in range(d[\"active_learning\"][\"M_cycles\"]):\n",
    "        df_cycle = df_selected_all[df_selected_all[\"selected_cycle\"]<=cycle].copy()\n",
    "        df_not_selected = df_pool[(df_pool[\"selected_cycle\"]<0) | (df_pool[\"selected_cycle\"]>cycle)].copy()\n",
    "        M = N - len(df_cycle)\n",
    "        df_cycle_greedy = df_not_selected.sort_values(f\"cycle_{cycle+1}_preds\", ascending=False).head(M).copy()\n",
    "        df_cycle_greedy = pd.concat([df_cycle, df_cycle_greedy])\n",
    "        top1_recall = df_cycle_greedy[\"top\"].sum()/df_pool[\"top\"].sum()\n",
    "        top1_precision = df_cycle_greedy[\"top\"].sum()/len(df_cycle_greedy[\"top\"])\n",
    "        top10_recall = df_cycle[\"top_10\"].sum()/df_pool[\"top_10\"].sum()\n",
    "        top10_precision = df_cycle[\"top_10\"].sum()/len(df_cycle[\"top_10\"])\n",
    "        \n",
    "        top_mean_1 = df_cycle_greedy.sort_values(\"DMS_score\", ascending=False).head(topk)[\"DMS_score\"].mean()\n",
    "        top_mean_2 = df_cycle_greedy.sort_values(\"DMS_score\", ascending=False).head(topk*2)[\"DMS_score\"].mean()\n",
    "        top_mean_3 = df_cycle_greedy.sort_values(\"DMS_score\", ascending=False).head(topk*3)[\"DMS_score\"].mean()\n",
    "        results.append({\"cycle\": cycle+1, \"recall\": top1_recall, \"precision\": top1_precision, \"recall_10\": top10_recall, \"precision_10\": top10_precision, \"top_mean_1\": top_mean_1,\"top_mean_2\": top_mean_2,\"top_mean_3\": top_mean_3})\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699aab3-37a4-46c1-96fa-2abed5f28072",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_job_df = pd.read_csv(\"../bindinggym_offline/jobs.csv\")\n",
    "dfs={}\n",
    "config_ds=[]\n",
    "for config_path in al_job_df[\"config\"]:\n",
    "    wdir=os.path.dirname(config_path)\n",
    "    with open(config_path) as f:\n",
    "        config_d = yaml.safe_load(f)\n",
    "    try:\n",
    "        if int(config_d[\"dms_index\"]) not in dms_indices:\n",
    "            continue\n",
    "        config_ds.append(config_d)\n",
    "        M=config_d[\"active_learning\"][\"M_cycles\"]\n",
    "        config_d[\"ablang\"]=\"bo4_ablang\" in config_path\n",
    "        dfs[wdir] = pd.read_csv(os.path.join(wdir,f\"predictions_cycle_{M}.csv\"))\n",
    "    except:\n",
    "        print(wdir,len(os.listdir(wdir))-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d21c29-692d-43eb-a0c9-14a9847a8bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame(config_ds)\n",
    "alconf = pd.DataFrame(config_df[\"active_learning\"].values.tolist())\n",
    "config_df[alconf.columns]=alconf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035ccb6-556e-4ddc-974f-2c89a15a7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmps = [config_df[config_df[\"dms_index\"]==i][\"tmp_path\"].values[0] for i in range(TASKNUM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1e825-7fee-4f72-81dc-f7102b3a11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_results = []\n",
    "proteinmpnn_results = []\n",
    "ablang2_results = []\n",
    "for i in range(TASKNUM):\n",
    "    tmp_path=tmps[i]\n",
    "    test_indices = dfs[tmp_path][dfs[tmp_path][\"is_test\"]].index\n",
    "    esm_test = esm_dfs[i].sort_values(\"esm2_t33_650M_UR50D\")[\"DMS_score\"].loc[test_indices]\n",
    "    proteinmpnn_test = proteinmpnn_dfs[i].sort_values(\"design_score\")[\"DMS_score\"].loc[test_indices]\n",
    "\n",
    "    proteinmpnn_result = calc_test(proteinmpnn_test, proteinmpnn_dfs[i][\"design_score\"].loc[test_indices])\n",
    "    esm_result = calc_test(esm_test, esm_dfs[i][\"esm2_t33_650M_UR50D\"].loc[test_indices])\n",
    "    ablang_result = calc_test(esm_test, ablang_dfs[i][\"cycle_0_preds\"].loc[test_indices])\n",
    "    esm_result[\"dms_index\"] = i\n",
    "    proteinmpnn_result[\"dms_index\"] = i\n",
    "    ablang_result[\"dms_index\"] = i\n",
    "    esm_results.append(esm_result)\n",
    "    proteinmpnn_results.append(proteinmpnn_result)\n",
    "    ablang2_results.append(ablang_result)\n",
    "\n",
    "esm_results = pd.DataFrame(esm_results)\n",
    "esm_results_mean = esm_results.mean(axis=0)\n",
    "proteinmpnn_results = pd.DataFrame(proteinmpnn_results)\n",
    "proteinmpnn_results_mean = proteinmpnn_results.mean(axis=0)\n",
    "\n",
    "ablang2_results = pd.DataFrame(ablang2_results)\n",
    "ablang2_results_mean = ablang2_results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eec842-9675-4cb7-a0b6-1f384f3872ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.01\n",
    "pool_esm_results = []\n",
    "pool_proteinmpnn_results = []\n",
    "pool_ablang2_results = []\n",
    "for i in range(TASKNUM):\n",
    "    df = dfs[tmps[i]]\n",
    "    df_pool = df[~df[\"is_test\"]].copy()\n",
    "    df_pool[\"top\"] = df_pool[\"DMS_score\"]>df_pool[\"DMS_score\"].quantile(1-p)\n",
    "    pool_indices = df[~df[\"is_test\"]].index\n",
    "    esm_pool = esm_dfs[i].loc[pool_indices].copy()\n",
    "    \n",
    "    esm_pool[\"top\"] = esm_pool[\"DMS_score\"]>esm_pool[\"DMS_score\"].quantile(1-p)\n",
    "    esm_pool = esm_pool.sort_values(\"esm2_t33_650M_UR50D\", ascending=False)\n",
    "    \n",
    "    proteinmpnn_pool = proteinmpnn_dfs[i].loc[pool_indices].copy()\n",
    "    proteinmpnn_pool[\"top\"] = proteinmpnn_pool[\"DMS_score\"]>proteinmpnn_pool[\"DMS_score\"].quantile(1-p)\n",
    "    proteinmpnn_pool = proteinmpnn_pool.sort_values(\"design_score\", ascending=False).reset_index()\n",
    "\n",
    "    ablang2_pool = ablang_dfs[i].loc[pool_indices].copy()\n",
    "    ablang2_pool[\"top\"] = ablang2_pool[\"DMS_score\"]>ablang2_pool[\"DMS_score\"].quantile(1-p)\n",
    "    ablang2_pool = ablang2_pool.sort_values(\"cycle_0_preds\", ascending=False).reset_index()\n",
    "    for n in range(1,601):\n",
    "        esm_top = esm_pool.head(n)\n",
    "        esm_top_recall = esm_top[\"top\"].sum()/df_pool[\"top\"].sum()\n",
    "        esm_top_precision = esm_top[\"top\"].sum()/len(esm_top[\"top\"])\n",
    "        esm_top_mean = esm_top.sort_values(\"DMS_score\", ascending=False).head(10)[\"DMS_score\"].mean()\n",
    "        pool_esm_results.append({\"dms_index\": i, \"cycle\": n, \"recall\": esm_top_recall, \"precision\": esm_top_precision, \"top_mean\": esm_top_mean})\n",
    "\n",
    "        proteinmpnn_top = proteinmpnn_pool.head(n)\n",
    "        proteinmpnn_top_recall = proteinmpnn_top[\"top\"].sum()/df_pool[\"top\"].sum()\n",
    "        proteinmpnn_top_precision = proteinmpnn_top[\"top\"].sum()/len(proteinmpnn_top[\"top\"])\n",
    "        proteinmpnn_top_mean = proteinmpnn_top.sort_values(\"DMS_score\", ascending=False).head(10)[\"DMS_score\"].mean()\n",
    "        pool_proteinmpnn_results.append({\"dms_index\": i, \"cycle\": n, \"recall\": proteinmpnn_top_recall, \"precision\": proteinmpnn_top_precision, \"top_mean\": proteinmpnn_top_mean})\n",
    "\n",
    "        ablang2_top = ablang2_pool.head(n)\n",
    "        ablang2_top_recall = ablang2_top[\"top\"].sum()/df_pool[\"top\"].sum()\n",
    "        ablang2_top_precision = ablang2_top[\"top\"].sum()/len(ablang2_top[\"top\"])\n",
    "        ablang2_top_mean = ablang2_top.sort_values(\"DMS_score\", ascending=False).head(10)[\"DMS_score\"].mean()\n",
    "        pool_ablang2_results.append({\"dms_index\": i, \"cycle\": n, \"recall\": ablang2_top_recall, \"precision\": ablang2_top_precision, \"top_mean\": ablang2_top_mean})\n",
    "\n",
    "pool_esm_results = pd.DataFrame(pool_esm_results)\n",
    "pool_proteinmpnn_results = pd.DataFrame(pool_proteinmpnn_results)\n",
    "pool_ablang2_results = pd.DataFrame(pool_ablang2_results)\n",
    "\n",
    "pool_esm_results_mean = pool_esm_results.groupby(\"cycle\").mean()\n",
    "pool_proteinmpnn_results_mean = pool_proteinmpnn_results.groupby(\"cycle\").mean()\n",
    "pool_ablang2_results_mean = pool_ablang2_results.groupby(\"cycle\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a09d55-47c5-4271-bfa7-53dfbb125ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_dfs=[]\n",
    "for i, d in config_df.iterrows():\n",
    "    try:\n",
    "        df = dfs[d[\"tmp_path\"]]\n",
    "        if d[\"dms_index\"] not in dms_indices:\n",
    "            continue\n",
    "        cycle_list=list(range(d[\"active_learning\"][\"M_cycles\"]+1))\n",
    "        test_metrics_df = compute_test_performance(df, cycle_list)\n",
    "        test_metrics_df[\"N_init\"]=d[\"active_learning\"][\"N_init\"]\n",
    "        test_metrics_df[\"N_per_cycle\"]=d[\"active_learning\"][\"N_per_cycle\"]\n",
    "        test_metrics_df[\"strategy\"]=d[\"active_learning\"][\"strategy\"]\n",
    "        test_metrics_df[\"dms_index\"]=d[\"dms_index\"]\n",
    "        test_metrics_df[\"model_type\"]=d[\"model_type\"]\n",
    "        test_metrics_df[\"tmp_path\"]=d[\"tmp_path\"]\n",
    "        test_metrics_df[\"noise_level\"]=d[\"noise_level\"]\n",
    "        test_metrics_df[\"ablang\"]=d[\"ablang\"]\n",
    "        test_metrics_df[\"use_dropout\"]=d[\"use_dropout\"]\n",
    "        test_metrics_df[\"logit_mode\"] = \"bo4_logits\" in d[\"tmp_path\"]\n",
    "        test_metrics_dfs.append(test_metrics_df)\n",
    "    except Exception as e:\n",
    "        print(i,e)\n",
    "        continue\n",
    "\n",
    "test_metrics_df_merge = pd.concat(test_metrics_dfs)\n",
    "test_metrics_df_merge[\"Training size\"] =  test_metrics_df_merge.apply(lambda x: (x[\"cycle\"]-1)*x[\"N_per_cycle\"]+x[\"N_init\"],axis=1)\n",
    "pool_metrics_dfs=[]\n",
    "for i, d in config_df.iterrows():\n",
    "    try:\n",
    "        df = dfs[d[\"tmp_path\"]]\n",
    "        if d[\"dms_index\"] not in dms_indices:\n",
    "            continue\n",
    "        cycle_list=list(range(d[\"active_learning\"][\"M_cycles\"]+1))\n",
    "        pool_metrics_df = calc_recall_precision(d, df, p=0.01)\n",
    "        pool_metrics_df_greedy = calc_recall_precision_greedy(d, df, p=0.01)\n",
    "        pool_metrics_dfx = pd.merge(pool_metrics_df, pool_metrics_df_greedy, on=[\"cycle\"], how=\"left\",suffixes=[\"\",\"_g\"])\n",
    "        pool_metrics_dfx[\"N_init\"]=d[\"active_learning\"][\"N_init\"]\n",
    "        pool_metrics_dfx[\"N_per_cycle\"]=d[\"active_learning\"][\"N_per_cycle\"]\n",
    "        pool_metrics_dfx[\"strategy\"]=d[\"active_learning\"][\"strategy\"]\n",
    "        pool_metrics_dfx[\"dms_index\"]=d[\"dms_index\"]\n",
    "        pool_metrics_dfx[\"model_type\"]=d[\"model_type\"]\n",
    "        pool_metrics_dfx[\"tmp_path\"]=d[\"tmp_path\"]\n",
    "        pool_metrics_dfx[\"noise_level\"]=d[\"noise_level\"]\n",
    "        pool_metrics_dfx[\"ablang\"]=d[\"ablang\"]\n",
    "        pool_metrics_dfx[\"use_dropout\"]=d[\"use_dropout\"]\n",
    "        pool_metrics_dfx[\"logit_mode\"] = \"bo4_logits\" in d[\"tmp_path\"]\n",
    "    \n",
    "        pool_metrics_dfs.append(pool_metrics_dfx)\n",
    "    except:\n",
    "        print(d[\"tmp_path\"])\n",
    "    \n",
    "\n",
    "pool_metrics_df_merge = pd.concat(pool_metrics_dfs)\n",
    "pool_metrics_df_merge[\"Training size\"] =  pool_metrics_df_merge.apply(lambda x: (x[\"cycle\"]-1)*x[\"N_per_cycle\"]+x[\"N_init\"],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f13116-2240-4177-962f-35a241c227f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_scores_metric_list = {}\n",
    "for metric in [\"ndcg\", \"spearman\", \"top_mean\", \"recall\", \"precision\"]:\n",
    "    baseline_scores_list = []\n",
    "    for dms_index in range(TASKNUM):\n",
    "        baseline_scores = {}\n",
    "        if metric in [\"ndcg\", \"spearman\"]:\n",
    "            baseline_scores[\"sequence\"] = esm_results[esm_results[\"dms_index\"]==dms_index][metric].values[0]\n",
    "            baseline_scores[\"proteinmpnn\"] = proteinmpnn_results[proteinmpnn_results[\"dms_index\"]==dms_index][metric].values[0]\n",
    "            baseline_scores[\"ablang2\"] = ablang2_results[ablang2_results[\"dms_index\"]==dms_index][metric].values[0]\n",
    "        elif metric in [\"top_mean\", \"recall\", \"precision\"]:\n",
    "            baseline_scores[\"sequence\"] = pool_esm_results[pool_esm_results[\"dms_index\"]==dms_index].set_index(\"cycle\")[metric].tolist()\n",
    "            baseline_scores[\"proteinmpnn\"] = pool_proteinmpnn_results[pool_proteinmpnn_results[\"dms_index\"]==dms_index].set_index(\"cycle\")[metric].tolist()\n",
    "            baseline_scores[\"ablang2\"] = pool_ablang2_results[pool_ablang2_results[\"dms_index\"]==dms_index].set_index(\"cycle\")[metric].tolist()\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid metric: {metric}\")\n",
    "        baseline_scores_list.append(baseline_scores)\n",
    "    baseline_scores_metric_list[metric] = baseline_scores_list\n",
    "baseline_scores_metric_list[\"top_mean_1\"]=baseline_scores_metric_list[\"top_mean\"]\n",
    "with open(\"../results/bindinggym_offline/baseline_scores_metric_list.json\", 'w') as f:\n",
    "    json.dump(baseline_scores_metric_list, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598169b-5d43-4a59-9134-4df18370928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_metrics_df_merge.to_csv(\"../results/bindinggym_offline/pool_metrics_df_merge.csv\", index=False)\n",
    "test_metrics_df_merge.to_csv(\"../results/bindinggym_offline/test_metrics_df_merge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4590947-b9c7-4970-8d53-0a9864ba70f8",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg39",
   "language": "python",
   "name": "pyg39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
